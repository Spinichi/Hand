{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc93060b",
   "metadata": {},
   "source": [
    "# KcELECTRA 모델 경량화 및 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652dfe5",
   "metadata": {},
   "source": [
    "1. F16으로 경량화\n",
    "2. bitsandbytes 8bit\n",
    "\n",
    "추론 속도 자체는 충분히 빨라서 굳이 최적화를 해야할 지 모르겠음. 일단 time으로 찍어 볼 예정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46f1916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: safetensors\n",
      "Version: 0.6.2\n",
      "Summary: \n",
      "Home-page: https://github.com/huggingface/safetensors\n",
      "Author: \n",
      "Author-email: Nicolas Patry <patry.nicolas@protonmail.com>\n",
      "License: \n",
      "Location: c:\\users\\ssafy\\desktop\\wang\\kcvenv\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: accelerate, peft, transformers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ssafy\\desktop\\wang\\kcvenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip show safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25c3ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ INT8 모델 변환 완료: ./best_model_INT8\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch, os\n",
    "\n",
    "model_path = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\Classifier_Model\"\n",
    "dst_path = \"./best_model_INT8\"\n",
    "\n",
    "# ✅ bitsandbytes 설정 (8비트 양자화)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,             # 8비트 양자화 활성화\n",
    "    llm_int8_threshold=6.0,        # outlier threshold (기본값 6.0)\n",
    "    llm_int8_has_fp16_weight=False # 완전 INT8로 저장\n",
    ")\n",
    "\n",
    "# ✅ 모델 로드 + 양자화 적용\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"   # 자동으로 GPU/CPU 분배\n",
    ")\n",
    "\n",
    "# ✅ 저장\n",
    "model.save_pretrained(dst_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.save_pretrained(dst_path)\n",
    "\n",
    "print(\"✅ INT8 모델 변환 완료:\", dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c77beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 카테고리 (모델의 class 순서)\n",
    "CATEGORIES = [\n",
    "    \"happy\",\n",
    "    \"embarrass\",\n",
    "    \"anger\",\n",
    "    \"unrest\",\n",
    "    \"damaged\",\n",
    "    \"sadness\",\n",
    "]\n",
    "\n",
    "# 이건 실제 csv에서 뽑아올 것.\n",
    "label_map = {\n",
    "    \"기쁨\": 0,     # happy\n",
    "    \"당황\": 1,     # embarrass\n",
    "    \"분노\": 2,     # anger\n",
    "    \"불안\": 3,     # unrest\n",
    "    \"상처\": 4,     # damaged\n",
    "    \"슬픔\": 5,     # sadness\n",
    "}\n",
    "\n",
    "NUM_LABELS = len(CATEGORIES)\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb157afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import time\n",
    "\n",
    "# 모델이랑 토크나이저 불러오기.\n",
    "# MODEL_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\best_model_INT8\"\n",
    "MODEL_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\Classifier_Model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR)\n",
    "model.eval().to(\"cpu\")\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(MODEL_DIR, device_map=\"cpu\")\n",
    "\n",
    "def predict_emotion(texts):\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "\n",
    "    device = \"cpu\"\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = F.softmax(outputs.logits, dim=-1)\n",
    "        preds = probs.argmax(dim=-1)\n",
    "    \n",
    "    results = {\n",
    "        \"text\": clean(text),\n",
    "        \"pred_label\": CATEGORIES[preds.item()],\n",
    "        \"probabilities\": {CATEGORIES[j]: round(probs[0][j].item(), 4) for j in range(len(CATEGORIES))}\n",
    "        }\n",
    "    \n",
    "    #여러 문장인 경우\n",
    "    # for i, text in enumerate(texts):\n",
    "    #     results.append({\n",
    "    #         \"text\": clean(text),\n",
    "    #         \"pred_label\": CATEGORIES[preds[i].item()],\n",
    "    #         \"probabilities\": {CATEGORIES[j]: round(probs[i][j].item(), 4) for j in range(len(CATEGORIES))}\n",
    "    #     })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee9e0be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 문장은 요즘 너무 무기력해요., 감정 분석은 {'happy': 0.0022, 'embarrass': 0.0375, 'anger': 0.1249, 'unrest': 0.4777, 'damaged': 0.141, 'sadness': 0.2167}, 걸린 시간은0.11554694175720215\n",
      "타겟 문장은 불안해서 잠이 안 와요., 감정 분석은 {'happy': 0.0023, 'embarrass': 0.0365, 'anger': 0.1329, 'unrest': 0.0528, 'damaged': 0.4974, 'sadness': 0.2781}, 걸린 시간은0.07091546058654785\n",
      "타겟 문장은 오늘 집에 가다가 오토바이에 치여서 다칠 뻔했어. 너무 짜증나, 감정 분석은 {'happy': 0.0012, 'embarrass': 0.0043, 'anger': 0.9781, 'unrest': 0.0033, 'damaged': 0.0076, 'sadness': 0.0055}, 걸린 시간은0.07818722724914551\n",
      "평균 추론 시간: 0.088초\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import mlflow\n",
    "\n",
    "sample = [\"요즘 너무 무기력해요.\", \"불안해서 잠이 안 와요.\", \"오늘 집에 가다가 오토바이에 치여서 다칠 뻔했어. 너무 짜증나\"]\n",
    "mlflow.set_tracking_uri(r\"file:\\\\\\C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\ai\\mlruns\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"inference_time_last\"):\n",
    "    try:\n",
    "        times = []\n",
    "        for i, text in enumerate(sample):\n",
    "            start = time.time()\n",
    "            result = predict_emotion(text)\n",
    "            end = time.time()\n",
    "            infer_time = end - start\n",
    "            times.append(infer_time)\n",
    "            \n",
    "            print(f'타겟 문장은 {text}, 감정 분석은 {result[\"probabilities\"]}, 걸린 시간은{infer_time}')\n",
    "            \n",
    "            mlflow.log_metric(\"inference_time\", infer_time, step=i)\n",
    "            \n",
    "        avg_time = sum(times) / len(times)\n",
    "        mlflow.log_metric(\"avg_inference_time\", avg_time)\n",
    "        print(f\"평균 추론 시간: {avg_time:.3f}초\")\n",
    "    finally:\n",
    "        mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c0aeda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA available: True\n",
      "Torch CUDA version: 12.1\n",
      "GPU name: NVIDIA GeForce RTX 4050 Laptop GPU\n",
      "Bitsandbytes version: 0.43.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "print(\"Torch CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Torch CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "print(\"Bitsandbytes version:\", bnb.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d0008e",
   "metadata": {},
   "source": [
    "# 경량화 평가"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kcvenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
