{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd8184a1",
   "metadata": {},
   "source": [
    "## 초기 환경 세팅 및 확인\n",
    "1. requirements.txt 및 MLflow 설치\n",
    "2. torch는 cuda버전을 사용하고 있으므로 사용자가 추가로 다운로드 필요\n",
    "3. 그래픽카드 사용 가능여부 확인\n",
    "    - get_device_name에서 안뜨면 그래픽카드 안잡힌것.\n",
    "    - 만약 안잡히면 !nvidia-smi 주석을 풀고 그래픽카드가 제대로 잡히는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477546cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04781b4",
   "metadata": {},
   "source": [
    "### 그래픽 카드 확인\n",
    "**torch로 그래픽카드가 잡히지 않을 때만 확인용으로 주석 제거 후 돌리기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fabb2",
   "metadata": {},
   "source": [
    "토치 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e78d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743a38c",
   "metadata": {},
   "source": [
    "CUDA 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525b52ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df27cf1",
   "metadata": {},
   "source": [
    "## 모델 가져오기\n",
    "- 현재 파일에서는 hugginface의 beomi/KcELECTRA-base 모델을 사용할 예정입니다.\n",
    "- 다른 모델을 사용하기 원할 경우 huggingface의 가이드에 따라 모델명을 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eb700e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForPreTraining\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ccfec",
   "metadata": {},
   "source": [
    "### 성능 향상을 위한 Text 정제\n",
    "- huggingface에서 개발자가 공개한 성능을 높이기 위한 데이터 전처리 과정입니다. 특수문자 및 이모지 등을 제거합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcbce7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f80ef",
   "metadata": {},
   "source": [
    "# KcELECTRA 확인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e455bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 오늘 선배한테 혼났어.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "model = AutoModelForPreTraining.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "\n",
    "sentence = \"나는 오늘 선배한테 혼났어.\"\n",
    "cleaned_sentence = clean(sentence)\n",
    "print(cleaned_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b5dda",
   "metadata": {},
   "source": [
    "# KoBERT-Senti5 모델 확인 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a855d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "\n",
    "# KoBERT의 원래 토크나이저 사용\n",
    "tokenizer = AutoTokenizer.from_pretrained('monologg/kobert')\n",
    "model = BertForSequenceClassification.from_pretrained('jeonghyeon97/koBERT-Senti5')\n",
    "\n",
    "# 예시 입력 (여러 문장 리스트)\n",
    "texts = [\n",
    "    \"오늘은 정말 행복한 하루야!\",\n",
    "    \"이거 정말 짜증나고 화난다.\",\n",
    "    \"그냥 그렇네.\",\n",
    "    \"왜 이렇게 슬프지?\",\n",
    "    \"기분이 좀 불안해.\"\n",
    "]\n",
    "\n",
    "# 입력 텍스트 토큰화\n",
    "inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# 예측\n",
    "outputs = model(**inputs)\n",
    "predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "# 결과 출력\n",
    "for text, prediction in zip(texts, predictions):\n",
    "    print(f\"입력: {text} -> 예측된 감정 레이블: {prediction.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981ed36a",
   "metadata": {},
   "source": [
    "## 학습 시킬 데이터 셋. json 형식으로 준비할 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"data/train.json\")\n",
    "\n",
    "def format_example(example):\n",
    "    return tokenizer(\n",
    "        f\"<|user|>: {example['instruction']}\\n<|assistant|>: {example['output']}\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(format_example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8699216",
   "metadata": {},
   "source": [
    "## 학습 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen3-finetuned\",     # 여기로 파인튜닝된 모델 저장\n",
    "    per_device_train_batch_size=2,      \n",
    "    gradient_accumulation_steps=8,\n",
    "    learning_rate=2e-4,\n",
    "    num_train_epochs=3,\n",
    "    fp16=True,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92421e79",
   "metadata": {},
   "source": [
    "## LORA 가중치 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ae0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # Qwen은 Q/V projection에 적용\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# 파라미터가 1~200만 정도 수준이면 잘 된거\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94f5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./qwen3-lora\")\n",
    "tokenizer.save_pretrained(\"./qwen3-lora\")\n",
    "\n",
    "from peft import merge_and_unload\n",
    "merged_model = merge_and_unload(model)\n",
    "merged_model.save_pretrained(\"./qwen3-merged\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kcvenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
