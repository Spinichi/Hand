{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04781b4",
   "metadata": {},
   "source": [
    "### 그래픽 카드 설정 및 확인\n",
    "**torch로 그래픽카드가 잡히지 않을 때만 확인용으로 주석 제거 후 돌리기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64fabb2",
   "metadata": {},
   "source": [
    "토치 버전 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf78f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.5.1+cu121\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3-Clause\n",
      "Location: c:\\users\\ssafy\\desktop\\wang\\kcvenv\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: accelerate, bitsandbytes, peft, torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ssafy\\desktop\\wang\\kcvenv\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip show torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a743a38c",
   "metadata": {},
   "source": [
    "CUDA 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "525b52ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "\n",
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b6ac6",
   "metadata": {},
   "source": [
    "### 로컬에선 GPU 지정 필요없음. GPU 서버에서는 주석 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9725c23-237d-4286-8a98-98dbb371a301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df27cf1",
   "metadata": {},
   "source": [
    "- 현재 파일에서는 hugginface의 beomi/KcELECTRA-base 모델을 사용할 예정입니다.\n",
    "- 해당 모델에 관한 정보는 config 파일을 통해 관리합니다.\n",
    "- 다른 모델을 사용하기 원할 경우 config의 MODEL_NAME을 huggingface의 가이드에 따라 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ccfec",
   "metadata": {},
   "source": [
    "## 성능 향상을 위한 Text 정제 코드\n",
    "- huggingface에서 개발자가 공개한 성능을 높이기 위한 데이터 전처리 과정입니다. 특수문자 및 이모지 등을 제거합니다\n",
    "- 불용어는 제거하지 않습니다. 감정 모델에서는 불용어 또한 중요한 데이터일 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcbce7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "emojis = ''.join(emoji.EMOJI_DATA.keys())\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣{emojis}]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from soynlp.normalizer import repeat_normalize\n",
    "\n",
    "pattern = re.compile(f'[^ .,?!/@$%~％·∼()\\x00-\\x7Fㄱ-ㅣ가-힣]+')\n",
    "url_pattern = re.compile(\n",
    "    r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()@:%_\\+.~#?&//=]*)')\n",
    "\n",
    "def clean(x): \n",
    "    x = pattern.sub(' ', x)\n",
    "    x = emoji.replace_emoji(x, replace='') #emoji 삭제\n",
    "    x = url_pattern.sub('', x)\n",
    "    x = x.strip()\n",
    "    x = repeat_normalize(x, num_repeats=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552f80ef",
   "metadata": {},
   "source": [
    "### 텍스트 정제 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e455bdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나는 오늘 선배한테 혼났어 .\n"
     ]
    }
   ],
   "source": [
    "sentence = \"나는 오늘 선배한테 혼났어 ★.\"\n",
    "cleaned_sentence = clean(sentence)\n",
    "print(cleaned_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb656dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['depression', 'nervous', 'guilt', 'motivation', 'cognitive_decline', 'somatic', 'trauma', 'background']\n"
     ]
    }
   ],
   "source": [
    "sentiment_label = {\n",
    "    # 우울함, 무기력력\n",
    "    \"depression\": [\n",
    "        \"depressive_mood\", \"anhedonia\", \"worthlessness\", \"negative_self-image\"\n",
    "    ],\n",
    "    # 불안, 긴장장\n",
    "    \"nervous\": [\n",
    "        \"loss_of_control\", \"emotional_requlation\", \"coping\"\n",
    "    ],\n",
    "    # 죄책감·수치심·자책 관련\n",
    "    \"guilt\": [\n",
    "        \"guilt\", \"belief\"\n",
    "    ],\n",
    "    # 동기·회복 기대 관련\n",
    "    \"motivation\": [\n",
    "        \"motivation_for_change\", \"unrealistic_recovery_expectations\", \"belief\"\n",
    "    ],\n",
    "    # 인지 저하·비현실적 사고 관련\n",
    "    \"cognitive_decline\": [\n",
    "        \"impaired_cognition\", \"unrealistic_recovery_expectations\"\n",
    "    ],\n",
    "    # 신체적 증상 및 행동 변화 관련\n",
    "    \"somatic\": [\n",
    "        \"fatigue\", \"psychomotor_changes\", \"sleep_disturbance\", \"weight_appetite\", \"lifestyle\"\n",
    "    ],\n",
    "    # 외상·트라우마 관련\n",
    "    \"trauma\": [\n",
    "        \"trauma_experience\", \"loss_of_control\", \"emotional_requlation\"\n",
    "    ],\n",
    "    # 환경·가족·기저질환 등 배경 요인\n",
    "    \"background\": [\n",
    "        \"family_history\", \"underlying_physical_condition\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "Emotion_Classification = list(sentiment_label.keys())\n",
    "\n",
    "# json 파일을 까서 세부 감정분류를 대분류로 매핑시키기 위한 코드\n",
    "def class_target(item: list):\n",
    "    y = []\n",
    "    for category, sub_label in Emotion_Classification.items():\n",
    "        val = 0\n",
    "        for sub in sub_label:\n",
    "            if sub in item and item[sub] > 0:\n",
    "                val = 1\n",
    "                break\n",
    "            y.append(val)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8699216",
   "metadata": {},
   "source": [
    "## 학습 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd79d0f",
   "metadata": {},
   "source": [
    "#### 1. 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "from config import ModelConfig as cf\n",
    "\n",
    "model_name = cf.MODEL_NAME\n",
    "DATA_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\KcELECTRA\\data\\Aftre_processed\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\SSAFY\\Desktop\\WANG\\S13P31A106\\KcELECTRA\\checkpoints\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 모델 설정\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(Emotion_Classification),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317163a9",
   "metadata": {},
   "source": [
    "#### 2. 추론 카테고리 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dcef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감정 카테고리\n",
    "CATEGORIES = [\n",
    "    \"depression\", \"nervous\", \"guilt\", \"motivation\",\n",
    "    \"cognitive_decline\", \"somatic\", \"trauma\", \"background\"\n",
    "]\n",
    "NUM_LABELS = len(CATEGORIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fb5873",
   "metadata": {},
   "source": [
    "#### 3. 데이터셋 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d5e5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, json_files, tokenizer, max_len=256):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        for path in json_files:\n",
    "            with open(path, \"r\", encoding=\"utf-8-sig\") as f:\n",
    "                samples = json.load(f)\n",
    "            for s in samples:\n",
    "                if not s.get(\"text\") or not s.get(\"labels\"):\n",
    "                    continue\n",
    "                text = s[\"text\"].strip()\n",
    "                labels = s[\"labels\"]\n",
    "                # 8개 카테고리 모두 포함 (없는 건 0)\n",
    "                y = [labels.get(cat, 0) for cat in CATEGORIES]\n",
    "                self.data.append({\"text\": text, \"labels\": y})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        enc = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(item[\"labels\"], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d5673",
   "metadata": {},
   "source": [
    "#### 4.학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = 1 / (1 + np.exp(-logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    micro = precision_recall_fscore_support(labels, preds, average=\"micro\", zero_division=0)\n",
    "    macro = precision_recall_fscore_support(labels, preds, average=\"macro\", zero_division=0)\n",
    "    samples_f1 = f1_score(labels, preds, average=\"samples\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"micro_f1\": micro[2],\n",
    "        \"macro_f1\": macro[2],\n",
    "        \"samples_f1\": samples_f1\n",
    "    }\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 파일 분할 (세션 단위)\n",
    "files = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith(\".json\")]\n",
    "random.shuffle(files)\n",
    "split_idx = int(len(files) * 0.8)\n",
    "train_files, val_files = files[:split_idx], files[split_idx:]\n",
    "\n",
    "train_ds = EmotionDataset(train_files, tokenizer)\n",
    "val_ds = EmotionDataset(val_files, tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=NUM_LABELS,\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"macro_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"none\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(os.path.join(OUTPUT_DIR, \"best_model\"))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"best_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0503d1",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d965a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text: str):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        probs = torch.sigmoid(logits).squeeze().tolist()\n",
    "    return {CATEGORIES[i]: round(float(probs[i]), 3) for i in range(NUM_LABELS)}\n",
    "\n",
    "print(predict_emotion(\"요즘 너무 무기력하고 잠도 잘 안 와요.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92421e79",
   "metadata": {},
   "source": [
    "## LORA 가중치 병합"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kcvenv (3.10.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
